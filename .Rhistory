plot(fitted(linearlog), residuals(linearlog)) #qual Ã© a chamada para este grÃ¡fico no ggplot?
ggplot(data = regb1, mapping = aes(x = Diam, y = Vol)) +
geom_point() +
geom_smooth(data = regb1, method = lm, se = F)
library(ggplot2)
ggplot(data = linearlog, mapping = aes(x = logtime, y = prop)) +
geom_point() +
geom_smooth(data =  linearlog, method = lm, se = F)
reg42b2 <- lm(data = bluegills, length ~ age + I(age^2))
summary(reg42b2)
ggplot(data = reg42b2, mapping = aes(x = age, y = length)) +
geom_point() +
stat_smooth(method = lm, formula = y ~ x + I(x^2), se = T)
plot(reg42b2)
summary(reg42b)
summary(reg42b2)
reg42b2 <- lm(data = bluegills, length ~ age + I(age^2))
setwd("./lista5")
bluegills <- read.delim("bluegills.txt")
reg42b2 <- lm(data = bluegills, length ~ age + I(age^2))
summary(reg42b2)
library(ggplot)
library(ggplot2)
ggplot(data = reg42b2, mapping = aes(x = age, y = length)) +
geom_point() +
stat_smooth(method = lm, formula = y ~ x + I(x^2), se = T)
ggplot(data = reg42b2, mapping = aes(x = age, y = length)) +
geom_point() +
stat_smooth(method = lm, formula = y ~ x + I(x^2), se = F)
plot(reg42b2)
summary(reg42b2)
summary(reg42b)
reg42b <- lm(data = bluegills, length ~ age)
summary(reg42b)
install.packages("aod")
library(aod)
library(ggplot2)
# carregando o banco de dados do exemplo
db5 <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
# visualização das primeiras linhas do banco de dados
head(db5)
# estatisticas descritivas das variáveis
summary(db5)
?saplly
# calculando os desvios padrão e aplicando-os às variáveis
sapply(db5, sd)
# tabela de contingência das variáveis dependentes e independente
xtabs(~admit + rank, data = db5)
db5$rank <- factor(db5$rank)
logit1 <- glm(admit ~ gre + gpa + rank, data = db5, family = "binomial")
summary(logit1)
# intervalos de confiança
confint(logit1)
# intervalos de confiança utilizando os erros padrão
confint.default(logit1)
# verificando o efeito da variável "rank"
wald.test(b = coef(logit1), Sigma = vcov(logit1), Terms = 4 : 6)
# criando um vetor para fazer interagir com o modelo
1 <- cbind(0, 0, 0, 1, -1, 0)
# criando um vetor para fazer interagir com o modelo
1 <- cbind(0, 0, 0, 1, -1, 0,)
# criando um vetor para fazer interagir com o modelo
1 <- cbind(0, 0, 0, 1, -1, 0,)
wald.test(b = coef(logit1), Sigma = vcov(logit1), L = 1)
# criando um vetor para fazer interagir com o modelo
1 <- cbind("0", "0", "0", "1", "-1", "0")
# criando um vetor para fazer interagir com o modelo
1 <- cbind(0, 0, 0, 1, -1, 0)
?cbind
# criando um vetor para fazer interagir com o modelo
1 <- cbind(0, 0, 0, 1, -1, 0)
library(tidyverse)
# exponenciando os coeficientes do modelo para interpretá-los como razões de chance
exp %>% coef(db5)
# exponenciando os coeficientes do modelo para interpretá-los como razões de chance
exp(coef(db5))
# exponenciando os coeficientes do modelo para interpretá-los como razões de chance
db5$rank <- numeric(db5$rank)
# exponenciando os coeficientes do modelo para interpretá-los como razões de chance
db5$rank <- as.numeric(db5$rank)
exp(coef(db5))
db5$rank <- factor(db5$rank)
# exponenciando os coeficientes do modelo para interpretá-los como razões de chance
exp(coef(logit1))
# colocando as odds ratios e os intervalos de confiança numa tabela
exp(cbind(OR = coef(logit1), confint(logit1)))
# criando um novo data frame com as probabilidades de de admissão
newdata <- with(db5, data.frame(gre = mean(gre), gpa = mean(gpa), rank = factor(1 : 4)))
newdata
# criando um novo data frame para calcular as probabilidades de de admissão
newdata1 <- with(db5, data.frame(gre = mean(gre), gpa = mean(gpa), rank = factor(1 : 4)))
newdata1$rankP <- predict(db5, newdata = newdata1, type = "response" )
newdata1$rankP <- predict(logit1, newdata = newdata1, type = "response" )
newdata1
# calculando probabilidades preditas variando as variáveis "rank" and "gre"
newdata2 <- with(db5, data.frame(gre = rep(seq(from = 200, to = 800, legth.out = 100),
4), gpa = mean(gpa), rank = factor(
rep(1 : 4, each = 100)
)))
# calculando probabilidades preditas variando as variáveis "rank" and "gre"
newdata2 <- with(db5, data.frame(gre = rep(seq(from = 200, to = 800, length.out = 100),
4), gpa = mean(gpa), rank = factor(
rep(1 : 4, each = 100)
)))
newdata3 <- cbind(newdata2, predict(logit1, newdata = newdata2, type = "link", se = T))
newdata3 <- within(newdata3, {
PredictedProb <- plogis(fit)
LL <- plogis(fit - (1.96*se.fit))
UL <- plogis(fit + (1.96))
})
# visualizando as primeiras linhas do objeto criado
head(newdata3)
# utilizando gráficos para uma melhor interpretação do modelo
ggplot(data = newdata3, aes(x = gre, y = PredictedProb)) +
geom_ribbon(aes(ymin = LL, ymax = UL, fill = rank), alpha = 0.2) +
geom_line(aes(colour = rank), size = 1)
# verificando tstatistic
with(logit1, null.deviance - deviance)
# graus de liberdade da diferença entre os modelos
with(logit1, df.null - df.residual)
# obtendo p-value
with(logit1, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = F))
# log likelihood
logLik(logit1)
library(foreign)
install.packages(nnet)
install.packages("nnet")
library(nnet)
library(ggplot2)
install.packages("reshape2")
library(reshape2)
ml <- read.dta("https://stats.idre.ucla.edu/stat/data/hsbdemo.dta")
with(data = ml, table(ses, prog))
SD = sd(x))))
SD = sd(x)))
with(data = ml, do.call(rbind, tapply(write, prog, function(x) c(M = mean(x),
SD = sd(x)))))
ml$prog2 <- relevel(ml$prog, ref = "academic")
test <- multinom(prog2 ~ ses + write, data = ml)
summary(test)
z <- summary(test)$coefficients/summary(test)$standard.errors
z
p <- (1 - pnorm(abs(z), 0, 1)) * 2
p
exp(coef(test))
head(pp <- fitted(test))
dses <- data.frame(ses = c("low", "middle", "high"), write = mean(ml$write))
predict(test, newdata = dses, "probs")
dwrite <- data.frame(ses = rep(c("low", "middle", "high"), each = 41),
write = rep(c(30 : 70)))
pp.write <- cbind(dwrite, predict(test, newdata = dwrite, type = "probs", se = T))
by(pp.write[, 3 : 5], pp.write$ses, colMeans)
head(lpp)
lpp <- melt(pp.write, id.vars = c("ses", "write"), value.name = "probability")
head(lpp)
ggplot(data = lpp, aes(x = write, y = probability, colour = ses)) +
geom_line() +
facet_grid(variable ~ ., scales = "free")
library(effects)
library(tidyverse)
save.image("~/GitHub/analisedados/lista8/8-lista-ad-ufpe-lucas-miranda.RData")
library(fields)
library(car)
banco <- read.csv("C:/Users/test/Documents/GitHub/analisedados/lista6/simula.correto.csv", header= T )
banco2 <- read.csv("C:/Users/test/Documents/GitHub/analisedados/lista6/simula.errado.csv", header=T)
attach(banco)
# As duas linhas abaixo produzem uma tabela descritiva com as principais medidas
# de tendencia central e de dispers?o das vari?veis produzidas.
variav.descrit <- data.frame(y, x1, x2, x3)
t(stats(variav.descrit))
par(mfrow = c(1,1))
boxplot(y, x1, x2, names = c('Y','X','X2'), ylim = c(-20,20))
par(mfrow = c(1,3))
hist(y, main = "Histograma de Y")
hist(x1, main = "Histograma de X1")
hist(x2, main ="Histograma de X2")
modelo.1 <- lm(y ~ x1)
modelo.2 <- lm(y ~ x1 + x2)
modelo.3 <- lm(y ~ x2 + x3)
modelo.4 <- lm(y ~ x1 + x3)
modelo.f <- lm(y ~ x1 + x2 + x3)
# Tabela da ANOVA
tab.ANOVA <- function(modelo, gln, gld) {
# modelo - modelo de regressao testado
# gln - graus de liberdade do numerador
# gld - graus de liberdade do denominador
SSreg <- sum((y-mean(y))^2)
print(paste('SSreg:'))
print(SSreg)
RSS <- sum(modelo$res^2)
print(paste('RSS:'))
print(RSS)
F.teste <- ((SSreg-RSS)/(gln)/(RSS/gld))
print(paste('F:'))
print(F.teste)
print(paste('P-valor:'))
1-pf(F.teste, 3, 196)
}
# Tabela com os resultados da regress?o
summary(modelo.1)
# Gr?fico para a representa?ao dos intervalos de confian?a dos coeficientes estimados
par(mfrow = c(1,1))
betas <- coefficients(modelo.f)
IC <-  confint(modelo.f, level = 0.95)
y.axis <- seq(from = 1, to = length(betas))
plot(betas, y.axis, type = "p", pch = 19, xlab = "Magnitude dos Coeficientes",
ylab ="", axes = F, xlim = c(min(IC - .4), max(IC + .4)),
ylim = c(min(y.axis-.2), max(y.axis+.2)), cex = 1,yaxs = "i",xaxs = "i")
segments(IC[,1], y.axis, IC[,2], y.axis)
axis(1, at = seq(round(min(IC - .9)), round(max(IC + .9)), by = 0.1),
labels = seq(round(min(IC - .9)), round(max(IC + .9)), by = 0.1), tick=T, cex.axis = 1, mgp = c(2,.7,0))
axis(2, at = y.axis, label = names(betas), las = 1, tick = T, line = -.5, cex.axis = 1, mgp = c(2,.7,0))
abline(v=0, lty=2, col="red")
# Gr?fico para interpretar os coeficientes
novo.x <- data.frame(x1 = seq(min(x1), max(x1), length.out = dim(banco)[1]), x2 = mean(x2), x3 = mean(x3))
novo.x2 <- data.frame(x1 = mean(x1), x2 = seq(min(x2), max(x2), length.out = dim(banco)[1]),  x3 = mean(x3))
novo.x3 <- data.frame(x1 = mean(x1), x2 = mean(x2), x3 = seq(min(x3), max(x3), length.out = dim(banco)[1]))
par(mfrow = c(1,3))
y.predito <- predict(modelo.f, novo.x, interval = "confidence")
matplot(novo.x$x1, y.predito, lty = c(1,2,2), col = c('black', 'red', 'red'),
type = "l", ylab = "Valor predito de Y", xlab = "X")
abline(h=0, col='gray', lty=3)
y.predito <- predict(modelo.f, novo.x2, interval = "confidence")
matplot(novo.x2$x2, y.predito, lty = c(1,2,2), col = c('black', 'red', 'red'), type = "l", ylab = "Valor predito de Y", xlab = "X2")
abline(h=0, col = 'gray', lty = 3)
y.predito <- predict(modelo.f, novo.x3, interval = "confidence")
matplot(novo.x3$x3, y.predito, lty = c(1,2,2), col=c('black', 'red', 'red'), type = "l", ylab = "Valor predito de Y", xlab = "X3")
abline(h = 0, col = 'gray', lty = 3)
detach(banco)
modelo1 <- lm(y ~ x1 + x2 + x3, data = banco)
modelo2 <- lm(y ~ x1 + x2 + x3, data = banco2)
par(mfrow=c(1,2))
### Avaliando o peso de outliers ###
# Bonferonni p-valor para casos extremos
outlierTest(modelo1)
outlierTest(modelo2)
# qq plot para res?duos padronizados em t
qqPlot(modelo1, main = "QQ Plot 1")
qqPlot(modelo2, main = "QQ Plot 2")
### Avaliando Observa??es Influentes ###
# Gr?ficos Parciais (Partil Plots)
avPlots(modelo1)
avPlots(modelo2)
# Cook's D plot
# Identifica??o de valores D > 4/(n-k-1)
limite <- 4/((length(banco$x) - length(modelo1$coefficients) - 1))
plot(modelo1, which = 4, cook.levels = limite)
limite <- 4/((length(banco2$x) - length(modelo2$coefficients) - 1))
plot(modelo2, which = 4, cook.levels = limite)
# Gr?fico de Influ?ncia
influencePlot(modelo1, id.method = "identify", main = "Gr?fico de Influ?ncia 1", ylim = c(-6, 6), xlim = c(0, 0.25))
influencePlot(modelo2, id.method = "identify", main="Gr?fico de Influ?ncia 2", ylim = c(-6, 6 ), xlim = c(0, 0.25))
### Checando a Normalidade dos Res?duos ###
# distribution of studentized residuals
sresid <- studres(modelo1)
hist(sresid, freq = FALSE, ylim = c(0, 0.4), main = "Distribui??o dos Res?duos Padronizados 1")
xfit <- seq(min(sresid), max(sresid), length = 40)
yfit <- dnorm(xfit)
lines(xfit, yfit)
### Checando a Normalidade dos Res?duos ###
# distribution of studentized residuals
sresid <- studres(modelo1)
### Avaliando homoscedasticidade ###
# Teste para vari?ncia do erro n?o constante
ncvTest(modelo1)
ncvTest(modelo2)
# plot res?duos padronizados vs. valores preditos
spreadLevelPlot(modelo1)
spreadLevelPlot(modelo2)
### Avaliando N?o-linearidade ##
# component + residual plot
crPlots(modelo1)
crPlots(modelo2)
### Teste para Colinearidade ###
vif(modelo1) # variance inflation factors
sqrt(vif(modelo1)) > 2 # problem?
par(mfrow = c(1,2))
plot(banco$x1, banco$x2, xlab = 'x1', ylab = 'x2') # plot de correla??o
plot(banco2$x2, banco2$x5, xlab = 'x1', ylab = 'x5')
### Teste para autocorrela??o dos erros ###
durbinWatsonTest(modelo1)
reg1 <- lm(data = wordrecall, prop ~ time)
summary(reg1)
ggplot(data = reg1, mapping = aes(x = time, y = prop)) +
geom_point() +
geom_smooth(data = reg1, method = lm, se = F)
reg1 <- lm(data = wordrecall, prop ~ time)
##### QUESTÃO 7 #####
setwd("C:/Users/test/Documents/GitHub/analisedados/lista7")
db7 <- read.csv("sample.csv")
# verificando a estrutura da variável
str(db7$female)
# transformando a variável em fator
db7$female <- factor(db7$female)
# gerando o modelo
logit71 <- glm(data = db7, hon ~ female, family = "binomial")
logit73 <- glm(data = db7, hon ~ math + read + female, family = "binomial")
newdataq7 <- with(db7, data.frame(math = mean(math), read = mean(read),
female = factor(0 : 1)))
# criando nova variável no modelo para calcular as probabilidades preditas
newdataq7$femaleP <- predict(logit73, newdata = newdataq7, type = "response")
newdataq7
# novo data frame com os valores das variáveis "math" e "female" variando, a fim
# de verificar o comportamento do modelo com "read" permanencendo na média
newdataq72 <- with(db7, data.frame(math = rep(
seq(from = 20, to = 100,
length.out = 100), 4),
read = mean(read), female = factor(rep(0 : 1, each = 100))))
# data frame com os intervalos de confiança
newdataq73 <- cbind(newdataq72, predict(logit73, newdata = newdataq72,
type = "link", se = TRUE))
newdataq73 <- within(newdataq73, {
PredictedProb <- plogis(fit)
LL <- plogis(fit - (1.96 * se.fit))
UL <- plogis(fit + (1.96 * se.fit))
})
# plotando o gráfico
ggplot(newdataq73, aes(x = math, y = PredictedProb)) +
geom_ribbon(aes(ymin = LL, ymax = UL, fill = female), alpha = 0.2) +
geom_line(aes(colour = female), size = 1)
ml <- read.dta("https://stats.idre.ucla.edu/stat/data/hsbdemo.dta")
head(ml)
table(ml)
table(ml)
ml$prog3 <- relevel(ml$prog, ref = "vocation")
test2 <- multinom(prog3 ~ ses + write, data = ml)
summary(test2)
ml$prog4 <- relevel(ml$prog, ref = "general")
test3 <- multinom(prog4 ~ ses + write, data = ml)
summary(test3)
setwd("C:/Users/test/Documents/GitHub/analisedados/lista8")
db4 <- read.dta("nomocc2.dta")
head(db4)
table(db4)
head(db4)
with(data = db4, table(occ))
levels(db4$occ[levels(db4$occ) % in % c("Menial", "BlueCol", "Craft")] <- "Manual")
db4$occ[levels(db4$occ) % in % c("Menial", "BlueCol", "Craft")] <- "Manual"
db4$occ[levels(db4$occ) %in% c("Menial", "BlueCol", "Craft")] <- "Manual"
str(db4$occ)
db4$occ[levels(db4$occ) %in% c("Menial", "BlueCol", "Craft")] <- "Manual"
with(db4, table(occ))
db4 <- read.dta("nomocc2.dta")
with(data = db4, table(occ))
db41 <- list(Manual = c("Menial", "BlueCol", "Craft"))
for(i in 1: length(db41)) levels(db4)[levels(db4) %in% db41[[i]]] <- names(db41)[i]
View(db4)
View(db41)
